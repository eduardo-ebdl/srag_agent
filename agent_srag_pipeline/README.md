# ‚öôÔ∏è SRAG Pipeline Orchestration
> **Gerenciamento de Jobs e Workflows com Databricks Asset Bundles (DABs)**

Este m√≥dulo √© respons√°vel pela **Infraestrutura como C√≥digo** do projeto. Ele define, agenda e gerencia a execu√ß√£o autom√°tica dos notebooks de ingest√£o de dados.

---

## Workflow Definido: `extract_srag`

O pipeline principal foi configurado para garantir a atualiza√ß√£o mensal dos dados do OpenDataSUS.

* **üìÖ Agendamento:** Todo dia **16 do m√™s**, √†s **12:00** (Hor√°rio de Bras√≠lia).
* **üìß Notifica√ß√£o:** Envio de e-mail autom√°tico em caso de falha (`on_failure`).

### Cadeia de Execu√ß√£o (Tasks)

1.  **`extract_srag_task`**
    * *Fun√ß√£o:* Extrai dados brutos da fonte governamental.
    * *Par√¢metros:* `target_years: 2024,2025`
2.  **`load_srag_task`** *(Depende da anterior)*
    * *Fun√ß√£o:* Carrega os dados persistidos para a tabela `srag_raw` (Bronze).

---

## Guia de Deploy (CLI)

Para implantar ou atualizar este pipeline no Databricks Workspace:

```bash
# 1. Autenticar no Databricks
databricks configure

# 2. Validar a sintaxe do arquivo .yml
databricks bundle validate

# 3. Fazer o Deploy (Dev ou Prod)
databricks bundle deploy

# 4. (Opcional) For√ßar uma execu√ß√£o manual agora
databricks bundle run extract_srag
```
