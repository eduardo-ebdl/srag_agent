{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8af5d615-c692-48e8-9189-a2cd00c510db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-01-07 18:56:45] [INFO] === SETUP CARGA BRONZE (RAW -> DELTA) ===\n[2026-01-07 18:56:45] [INFO] Origem: /Volumes/srag_dev/raw/raw/srag_downloads\n[2026-01-07 18:56:45] [INFO] Destino: srag_dev.raw.srag_raw\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import traceback\n",
    "import unicodedata\n",
    "import re\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Inicializar spark\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Funções Utilitárias\n",
    "def log(msg: str, level: str = \"INFO\"):\n",
    "    \"\"\"Logger padronizado com timestamp.\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"[{timestamp}] [{level}] {msg}\")\n",
    "\n",
    "def normalize_col_name(col_name):\n",
    "    \"\"\"\n",
    "    Remove acentos e caracteres especiais dos nomes das colunas.\n",
    "    Ex: 'DT. NOTIFICAÇÃO' -> 'dt_notificacao'\n",
    "    \"\"\"\n",
    "    # Normaliza unicode (remove acentos)\n",
    "    n = unicodedata.normalize('NFKD', col_name).encode('ASCII', 'ignore').decode('utf-8').lower()\n",
    "    # Substitui tudo que não for letra/número por underscore\n",
    "    n = re.sub(r'[^a-z0-9]', '_', n)\n",
    "    # Remove underscores duplicados e das pontas\n",
    "    return re.sub(r'_+', '_', n).strip('_')\n",
    "\n",
    "# Widgets\n",
    "try:\n",
    "    dbutils.widgets.text(\"catalog\", \"srag_dev\", \"1. Catálogo\")\n",
    "    dbutils.widgets.text(\"schema\", \"raw\", \"2. Schema\")\n",
    "    dbutils.widgets.text(\"table_name\", \"srag_raw\", \"3. Tabela Destino\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Parâmetros\n",
    "catalog = dbutils.widgets.get(\"catalog\")\n",
    "schema = dbutils.widgets.get(\"schema\")\n",
    "table_name = dbutils.widgets.get(\"table_name\")\n",
    "\n",
    "# Caminhos\n",
    "volume_path = f\"/Volumes/{catalog}/{schema}/raw/srag_downloads\"\n",
    "bronze_table = f\"{catalog}.{schema}.{table_name}\"\n",
    "\n",
    "# Log Inicial\n",
    "log(\"--- SETUP CARGA BRONZE (RAW -> DELTA) ---\")\n",
    "log(f\"Origem: {volume_path}\")\n",
    "log(f\"Destino: {bronze_table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9655312b-0679-45de-9c99-b4a82a09965a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-01-07 18:56:45] [INFO] --- Iniciando leitura e transformação ---\n[2026-01-07 18:57:17] [INFO] Leitura concluída. Schema normalizado com 196 colunas.\n"
     ]
    }
   ],
   "source": [
    "# Leitura e Tratamento\n",
    "\n",
    "log(\"--- Iniciando leitura e transformação ---\")\n",
    "\n",
    "try:\n",
    "    # Leitura CSV (DataSUS: ; e latin1)\n",
    "    df_raw = (\n",
    "        spark.read\n",
    "        .format(\"csv\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"delimiter\", \";\")          \n",
    "        .option(\"encoding\", \"latin1\")\n",
    "        .option(\"inferSchema\", \"false\")\n",
    "        .option(\"recursiveFileLookup\", \"true\") # Garante leitura de todos arquivos no path\n",
    "        .load(volume_path)\n",
    "    )\n",
    "\n",
    "    # Padronização de Colunas\n",
    "    # Aplica a função de normalização em todas as colunas\n",
    "    new_cols = [normalize_col_name(c) for c in df_raw.columns]\n",
    "    df_renamed = df_raw.toDF(*new_cols)\n",
    "\n",
    "    # Resiliência de Tipos (Tudo String)\n",
    "    df_casted = df_renamed.select(\n",
    "        [F.col(c).cast(StringType()) for c in df_renamed.columns]\n",
    "    )\n",
    "\n",
    "    # Colunas de Auditoria\n",
    "    df_final = df_casted \\\n",
    "        .withColumn(\"source_file\", F.col(\"_metadata.file_path\")) \\\n",
    "        .withColumn(\"ingestion_at\", F.current_timestamp())\n",
    "\n",
    "    # Validação\n",
    "    if df_final.isEmpty():\n",
    "        raise ValueError(\"O DataFrame está vazio. Verifique se há arquivos na pasta de origem.\")\n",
    "\n",
    "    log(f\"Leitura concluída. Schema normalizado com {len(df_final.columns)} colunas.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    log(f\"FALHA NA LEITURA: {traceback.format_exc()}\", level=\"ERROR\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a386c73d-e983-4a6e-baf6-15840d2dd25f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-01-07 18:58:19] [INFO] --- Escrevendo na tabela Delta: srag_dev.raw.srag_raw ---\n[2026-01-07 18:58:39] [SUCCESS] ✅ SUCESSO! Carga finalizada.\n[2026-01-07 18:58:39] [INFO] Total de registros na Bronze: 316945\n"
     ]
    }
   ],
   "source": [
    "# Escrita Bronze\n",
    "\n",
    "log(f\"--- Escrevendo na tabela Delta: {bronze_table} ---\")\n",
    "\n",
    "try:\n",
    "    (\n",
    "        df_final.write\n",
    "        .format(\"delta\")\n",
    "        .mode(\"overwrite\")\n",
    "        .option(\"overwriteSchema\", \"true\")\n",
    "        .option(\"userMetadata\", \"Carga Automática Pipeline SRAG\") \n",
    "        .saveAsTable(bronze_table)\n",
    "    )\n",
    "\n",
    "    # Otimização\n",
    "    spark.sql(f\"OPTIMIZE {bronze_table}\")\n",
    "\n",
    "    # Coletando métricas\n",
    "    total_rows = spark.table(bronze_table).count()\n",
    "    log(f\"✅ SUCESSO! Carga finalizada.\", level=\"SUCCESS\")\n",
    "    log(f\"Total de registros na Bronze: {total_rows}\")\n",
    "    \n",
    "    # Governança\n",
    "    spark.sql(f\"\"\"\n",
    "        COMMENT ON TABLE {bronze_table} IS \n",
    "        'Camada Bronze (Raw) de dados de SRAG. Origem: CSVs OpenDataSUS. \n",
    "        Tratamento: Encoding Latin1 -> UTF8, Nomes de colunas normalizados (snake_case), Tipagem 100% String.'\n",
    "    \"\"\")\n",
    "    \n",
    "except Exception as e:\n",
    "    log(f\"FALHA NA ESCRITA: {traceback.format_exc()}\", level=\"CRITICAL\")\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Load",
   "widgets": {
    "catalog": {
     "currentValue": "srag_dev",
     "nuid": "20ee5d88-fb1d-4bb8-90b1-2a88634f3d91",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "srag_dev",
      "label": "1. Catálogo",
      "name": "catalog",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "srag_dev",
      "label": "1. Catálogo",
      "name": "catalog",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "schema": {
     "currentValue": "raw",
     "nuid": "834732e1-daca-4160-a18c-b152a91cc558",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "raw",
      "label": "2. Schema",
      "name": "schema",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "raw",
      "label": "2. Schema",
      "name": "schema",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "table_name": {
     "currentValue": "srag_raw",
     "nuid": "3439e66d-24f8-4eb6-969f-4398ab934188",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "srag_raw",
      "label": "3. Tabela Destino",
      "name": "table_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "srag_raw",
      "label": "3. Tabela Destino",
      "name": "table_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}