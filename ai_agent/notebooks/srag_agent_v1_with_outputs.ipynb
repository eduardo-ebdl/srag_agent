{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ef39dfe-0f9e-4b3b-af1b-4473f27a1162",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (1.2.1)\nCollecting langchain\n  Downloading langchain-1.2.2-py3-none-any.whl.metadata (4.9 kB)\nRequirement already satisfied: langchain-community in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (0.4.1)\nRequirement already satisfied: langchain-core in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (1.2.6)\nRequirement already satisfied: langgraph in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (1.0.5)\nRequirement already satisfied: databricks-langchain in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (0.12.1)\nRequirement already satisfied: tavily-python in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (0.7.17)\nRequirement already satisfied: matplotlib in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (3.10.8)\nRequirement already satisfied: pandas in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (2.3.3)\nRequirement already satisfied: mlflow in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (3.8.1)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from langchain) (2.12.5)\nRequirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from langchain-community) (1.0.1)\nRequirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from langchain-community) (2.0.45)\nRequirement already satisfied: requests<3.0.0,>=2.32.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from langchain-community) (2.32.5)\nRequirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /databricks/python3/lib/python3.12/site-packages (from langchain-community) (6.0.2)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from langchain-community) (3.13.3)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /databricks/python3/lib/python3.12/site-packages (from langchain-community) (9.0.0)\nRequirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from langchain-community) (0.6.7)\nRequirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from langchain-community) (2.12.0)\nRequirement already satisfied: langsmith<1.0.0,>=0.1.125 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from langchain-community) (0.6.1)\nRequirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from langchain-community) (0.4.3)\nRequirement already satisfied: numpy>=1.26.2 in /databricks/python3/lib/python3.12/site-packages (from langchain-community) (2.1.3)\nRequirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from langchain-core) (1.33)\nRequirement already satisfied: packaging<26.0.0,>=23.2.0 in /databricks/python3/lib/python3.12/site-packages (from langchain-core) (24.1)\nRequirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from langchain-core) (4.15.0)\nRequirement already satisfied: uuid-utils<1.0,>=0.12.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from langchain-core) (0.12.0)\nRequirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from langgraph) (3.0.1)\nRequirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from langgraph) (1.0.5)\nRequirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from langgraph) (0.3.1)\nRequirement already satisfied: xxhash>=3.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from langgraph) (3.6.0)\nRequirement already satisfied: databricks-ai-bridge>=0.4.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from databricks-langchain) (0.11.0)\nRequirement already satisfied: databricks-mcp>=0.5.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from databricks-langchain) (0.5.1)\nRequirement already satisfied: databricks-sdk>=0.65.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from databricks-langchain) (0.77.0)\nRequirement already satisfied: databricks-vectorsearch>=0.50 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from databricks-langchain) (0.63)\nRequirement already satisfied: langchain-mcp-adapters>=0.1.13 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from databricks-langchain) (0.2.1)\nRequirement already satisfied: openai>=1.99.9 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from databricks-langchain) (2.14.0)\nRequirement already satisfied: unitycatalog-langchain>=0.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from unitycatalog-langchain[databricks]>=0.3.0->databricks-langchain) (0.3.0)\nRequirement already satisfied: tiktoken>=0.5.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from tavily-python) (0.12.0)\nRequirement already satisfied: httpx in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from tavily-python) (0.28.1)\nRequirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.12/site-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.12/site-packages (from matplotlib) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.12/site-packages (from matplotlib) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.3.1 in /databricks/python3/lib/python3.12/site-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: pillow>=8 in /databricks/python3/lib/python3.12/site-packages (from matplotlib) (11.1.0)\nRequirement already satisfied: pyparsing>=3 in /databricks/python3/lib/python3.12/site-packages (from matplotlib) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /databricks/python3/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.12/site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /databricks/python3/lib/python3.12/site-packages (from pandas) (2024.1)\nRequirement already satisfied: mlflow-skinny==3.8.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from mlflow) (3.8.1)\nRequirement already satisfied: mlflow-tracing==3.8.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from mlflow) (3.8.1)\nRequirement already satisfied: Flask-CORS<7 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from mlflow) (6.0.2)\nRequirement already satisfied: Flask<4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from mlflow) (3.1.2)\nRequirement already satisfied: alembic!=1.10.0,<2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from mlflow) (1.17.2)\nRequirement already satisfied: cryptography<47,>=43.0.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow) (43.0.3)\nRequirement already satisfied: docker<8,>=4.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from mlflow) (7.1.0)\nRequirement already satisfied: graphene<4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from mlflow) (3.4.3)\nRequirement already satisfied: gunicorn<24 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from mlflow) (23.0.0)\nRequirement already satisfied: huey<3,>=2.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from mlflow) (2.6.0)\nRequirement already satisfied: pyarrow<23,>=4.0.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow) (19.0.1)\nRequirement already satisfied: scikit-learn<2 in /databricks/python3/lib/python3.12/site-packages (from mlflow) (1.6.1)\nRequirement already satisfied: scipy<2 in /databricks/python3/lib/python3.12/site-packages (from mlflow) (1.15.1)\nRequirement already satisfied: cachetools<7,>=5.0.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow) (5.5.1)\nRequirement already satisfied: click<9,>=7.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow) (8.1.7)\nRequirement already satisfied: cloudpickle<4 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow) (3.0.0)\nRequirement already satisfied: fastapi<1 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow) (0.115.12)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow) (3.1.43)\nRequirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow) (6.6.0)\nRequirement already satisfied: opentelemetry-api<3,>=1.9.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow) (1.32.1)\nRequirement already satisfied: opentelemetry-proto<3,>=1.9.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow) (1.39.1)\nRequirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow) (1.32.1)\nRequirement already satisfied: protobuf<7,>=3.12.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow) (5.29.5)\nRequirement already satisfied: python-dotenv<2,>=0.19.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow) (1.2.1)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow) (0.5.3)\nRequirement already satisfied: uvicorn<1 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow) (0.34.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /databricks/python3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\nRequirement already satisfied: Mako in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\nRequirement already satisfied: cffi>=1.12 in /databricks/python3/lib/python3.12/site-packages (from cryptography<47,>=43.0.0->mlflow) (1.17.1)\nRequirement already satisfied: tabulate>=0.9.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from databricks-ai-bridge>=0.4.2->databricks-langchain) (0.9.0)\nRequirement already satisfied: mcp>=1.9.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from databricks-mcp>=0.5.1->databricks-langchain) (1.25.0)\nRequirement already satisfied: google-auth~=2.0 in /databricks/python3/lib/python3.12/site-packages (from databricks-sdk>=0.65.0->databricks-langchain) (2.40.0)\nRequirement already satisfied: deprecation>=2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from databricks-vectorsearch>=0.50->databricks-langchain) (2.1.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\nRequirement already satisfied: urllib3>=1.26.0 in /databricks/python3/lib/python3.12/site-packages (from docker<8,>=4.0.0->mlflow) (2.3.0)\nRequirement already satisfied: blinker>=1.9.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from Flask<4->mlflow) (1.9.0)\nRequirement already satisfied: itsdangerous>=2.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from Flask<4->mlflow) (2.2.0)\nRequirement already satisfied: jinja2>=3.1.2 in /databricks/python3/lib/python3.12/site-packages (from Flask<4->mlflow) (3.1.5)\nRequirement already satisfied: markupsafe>=2.1.1 in /databricks/python3/lib/python3.12/site-packages (from Flask<4->mlflow) (3.0.2)\nRequirement already satisfied: werkzeug>=3.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from Flask<4->mlflow) (3.1.4)\nRequirement already satisfied: graphql-core<3.3,>=3.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from graphene<4->mlflow) (3.2.7)\nRequirement already satisfied: graphql-relay<3.3,>=3.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from graphene<4->mlflow) (3.2.0)\nRequirement already satisfied: jsonpointer>=1.9 in /databricks/python3/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\nRequirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.1.0)\nRequirement already satisfied: ormsgpack>=1.12.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.12.1)\nRequirement already satisfied: orjson>=3.10.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11.5)\nRequirement already satisfied: anyio in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from httpx->tavily-python) (4.12.1)\nRequirement already satisfied: certifi in /databricks/python3/lib/python3.12/site-packages (from httpx->tavily-python) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /databricks/python3/lib/python3.12/site-packages (from httpx->tavily-python) (1.0.2)\nRequirement already satisfied: idna in /databricks/python3/lib/python3.12/site-packages (from httpx->tavily-python) (3.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /databricks/python3/lib/python3.12/site-packages (from httpcore==1.*->httpx->tavily-python) (0.14.0)\nRequirement already satisfied: requests-toolbelt>=1.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\nRequirement already satisfied: zstandard>=0.23.0 in /databricks/python3/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.23.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.99.9->databricks-langchain) (1.9.0)\nRequirement already satisfied: jiter<1,>=0.10.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from openai>=1.99.9->databricks-langchain) (0.12.0)\nRequirement already satisfied: sniffio in /databricks/python3/lib/python3.12/site-packages (from openai>=1.99.9->databricks-langchain) (1.3.0)\nRequirement already satisfied: tqdm>4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from openai>=1.99.9->databricks-langchain) (4.67.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /databricks/python3/lib/python3.12/site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.3.2)\nRequirement already satisfied: joblib>=1.2.0 in /databricks/python3/lib/python3.12/site-packages (from scikit-learn<2->mlflow) (1.4.2)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /databricks/python3/lib/python3.12/site-packages (from scikit-learn<2->mlflow) (3.5.0)\nRequirement already satisfied: greenlet>=1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.0)\nRequirement already satisfied: regex>=2022.1.18 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from tiktoken>=0.5.1->tavily-python) (2025.11.3)\nRequirement already satisfied: unitycatalog-ai in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from unitycatalog-langchain>=0.3.0->unitycatalog-langchain[databricks]>=0.3.0->databricks-langchain) (0.3.2)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.12/site-packages (from cffi>=1.12->cryptography<47,>=43.0.0->mlflow) (2.21)\nRequirement already satisfied: starlette<0.47.0,>=0.40.0 in /databricks/python3/lib/python3.12/site-packages (from fastapi<1->mlflow-skinny==3.8.1->mlflow) (0.46.2)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /databricks/python3/lib/python3.12/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.8.1->mlflow) (4.0.11)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /databricks/python3/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk>=0.65.0->databricks-langchain) (0.2.8)\nRequirement already satisfied: rsa<5,>=3.1.4 in /databricks/python3/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk>=0.65.0->databricks-langchain) (4.9.1)\nRequirement already satisfied: zipp>=0.5 in /databricks/python3/lib/python3.12/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.8.1->mlflow) (3.21.0)\nRequirement already satisfied: jsonschema>=4.20.0 in /databricks/python3/lib/python3.12/site-packages (from mcp>=1.9.1->databricks-mcp>=0.5.1->databricks-langchain) (4.23.0)\nRequirement already satisfied: pyjwt>=2.10.1 in /databricks/python3/lib/python3.12/site-packages (from pyjwt[crypto]>=2.10.1->mcp>=1.9.1->databricks-mcp>=0.5.1->databricks-langchain) (2.10.1)\nRequirement already satisfied: python-multipart>=0.0.9 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from mcp>=1.9.1->databricks-mcp>=0.5.1->databricks-langchain) (0.0.21)\nRequirement already satisfied: sse-starlette>=1.6.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from mcp>=1.9.1->databricks-mcp>=0.5.1->databricks-langchain) (3.0.3)\nRequirement already satisfied: deprecated>=1.2.6 in /databricks/python3/lib/python3.12/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==3.8.1->mlflow) (1.2.13)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.53b1 in /databricks/python3/lib/python3.12/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.8.1->mlflow) (0.53b1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /databricks/python3/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.0.0)\nRequirement already satisfied: nest-asyncio in /databricks/python3/lib/python3.12/site-packages (from unitycatalog-ai->unitycatalog-langchain>=0.3.0->unitycatalog-langchain[databricks]>=0.3.0->databricks-langchain) (1.6.0)\nRequirement already satisfied: unitycatalog-client in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from unitycatalog-ai->unitycatalog-langchain>=0.3.0->unitycatalog-langchain[databricks]>=0.3.0->databricks-langchain) (0.3.1)\nRequirement already satisfied: databricks-connect<17.1,>=15.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from unitycatalog-ai[databricks]; extra == \"databricks\"->unitycatalog-langchain[databricks]>=0.3.0->databricks-langchain) (17.0.10)\nRequirement already satisfied: googleapis-common-protos>=1.65.0 in /databricks/python3/lib/python3.12/site-packages (from databricks-connect<17.1,>=15.1.0->unitycatalog-ai[databricks]; extra == \"databricks\"->unitycatalog-langchain[databricks]>=0.3.0->databricks-langchain) (1.65.0)\nRequirement already satisfied: grpcio-status>=1.67.0 in /databricks/python3/lib/python3.12/site-packages (from databricks-connect<17.1,>=15.1.0->unitycatalog-ai[databricks]; extra == \"databricks\"->unitycatalog-langchain[databricks]>=0.3.0->databricks-langchain) (1.67.0)\nRequirement already satisfied: grpcio>=1.67.0 in /databricks/python3/lib/python3.12/site-packages (from databricks-connect<17.1,>=15.1.0->unitycatalog-ai[databricks]; extra == \"databricks\"->unitycatalog-langchain[databricks]>=0.3.0->databricks-langchain) (1.67.0)\nRequirement already satisfied: py4j<0.10.9.10,>=0.10.9.7 in /databricks/python3/lib/python3.12/site-packages (from databricks-connect<17.1,>=15.1.0->unitycatalog-ai[databricks]; extra == \"databricks\"->unitycatalog-langchain[databricks]>=0.3.0->databricks-langchain) (0.10.9.9)\nRequirement already satisfied: setuptools>=68.0.0 in /usr/local/lib/python3.12/dist-packages (from databricks-connect<17.1,>=15.1.0->unitycatalog-ai[databricks]; extra == \"databricks\"->unitycatalog-langchain[databricks]>=0.3.0->databricks-langchain) (74.0.0)\nRequirement already satisfied: wrapt<2,>=1.10 in /databricks/python3/lib/python3.12/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==3.8.1->mlflow) (1.17.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /databricks/python3/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.8.1->mlflow) (5.0.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /databricks/python3/lib/python3.12/site-packages (from jsonschema>=4.20.0->mcp>=1.9.1->databricks-mcp>=0.5.1->databricks-langchain) (2023.7.1)\nRequirement already satisfied: referencing>=0.28.4 in /databricks/python3/lib/python3.12/site-packages (from jsonschema>=4.20.0->mcp>=1.9.1->databricks-mcp>=0.5.1->databricks-langchain) (0.30.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /databricks/python3/lib/python3.12/site-packages (from jsonschema>=4.20.0->mcp>=1.9.1->databricks-mcp>=0.5.1->databricks-langchain) (0.22.3)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /databricks/python3/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk>=0.65.0->databricks-langchain) (0.4.8)\nRequirement already satisfied: aiohttp-retry>=2.8.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2b56d053-98d8-4099-a504-7850836ece7e/lib/python3.12/site-packages (from unitycatalog-client->unitycatalog-ai->unitycatalog-langchain>=0.3.0->unitycatalog-langchain[databricks]>=0.3.0->databricks-langchain) (2.9.1)\nDownloading langchain-1.2.2-py3-none-any.whl (105 kB)\nInstalling collected packages: langchain\n  Attempting uninstall: langchain\n    Found existing installation: langchain 1.2.1\n    Uninstalling langchain-1.2.1:\n      Successfully uninstalled langchain-1.2.1\nSuccessfully installed langchain-1.2.2\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# Instalação das bibliotecas de Orquestração (LangChain/Graph), Conectores (Databricks) e Pesquisa (Tavily).\n",
    "%pip install -U langchain langchain-community langchain-core langgraph databricks-langchain tavily-python matplotlib pandas mlflow\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d70594b0-22fb-4dc1-b2f9-89f02c6d02b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-01-07 20:07:58] [SYSTEM] ⚙️ Bibliotecas importadas e Logger configurado com sucesso.\n"
     ]
    }
   ],
   "source": [
    "# Importações\n",
    "\n",
    "# Bibliotecas padrão\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "# Dados e visualização\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Spark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, year\n",
    "\n",
    "# LangChain e LLMs\n",
    "from langchain.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "from langchain_core.messages import SystemMessage\n",
    "from databricks_langchain import ChatDatabricks\n",
    "\n",
    "# Serviços externos e ML\n",
    "from tavily import TavilyClient\n",
    "import mlflow\n",
    "\n",
    "# Configuração de Log\n",
    "def log(msg: str, level: str = \"INFO\"):\n",
    "    \"\"\"\n",
    "    Logger padronizado para rastreabilidade de execução.\n",
    "    Formato: [YYYY-MM-DD HH:MM:SS] [LEVEL] Icon Mensagem\n",
    "    \"\"\"\n",
    "    # Configuração de Fuso Horário (BRT)\n",
    "    fuso_br = timezone(timedelta(hours=-3))\n",
    "    timestamp = datetime.now(fuso_br).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    # Ícones visuais para facilitar leitura rápida dos logs\n",
    "    icons = {\n",
    "        \"INFO\": \"ℹ️\", \n",
    "        \"WARN\": \"⚠️\", \n",
    "        \"ERROR\": \"❌\", \n",
    "        \"SUCCESS\": \"✅\", \n",
    "        \"SYSTEM\": \"⚙️\",\n",
    "        \"TOOL\": \"\uD83D\uDEE0️\",\n",
    "        \"AI\": \"\uD83E\uDD16\"\n",
    "    }\n",
    "    icon = icons.get(level, \"\")\n",
    "    \n",
    "    print(f\"[{timestamp}] [{level}] {icon} {msg}\")\n",
    "\n",
    "log(\"Bibliotecas importadas e Logger configurado com sucesso.\", \"SYSTEM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cf0b0c2-cbad-4f5a-8726-93052e2b8351",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-01-07 20:08:15] [SUCCESS] ✅ MLOps Ativado. Experiment Path: /Users/eduardobdel@gmail.com/srag_agent_monitoring\n"
     ]
    }
   ],
   "source": [
    "# Define o experimento\n",
    "\n",
    "username = spark.sql(\"SELECT current_user()\").collect()[0][0]\n",
    "experiment_path = f\"/Users/{username}/srag_agent_monitoring\"\n",
    "mlflow.set_experiment(experiment_path)\n",
    "\n",
    "# Habilita o rastreamento automático para LangChain (capturar inputs, outputs, traces)\n",
    "mlflow.langchain.autolog()\n",
    "\n",
    "log(f\"MLOps Ativado. Experiment Path: {experiment_path}\", \"SUCCESS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c79805a-fffb-4e07-b9af-d7b20d7ca16e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-01-07 20:08:15] [SYSTEM] ⚙️ Ambiente de Dados Configurado.\n[2026-01-07 20:08:15] [INFO] ℹ️ Caminho do Volume: /Volumes/srag_prod/gold/volume_imagens\n[2026-01-07 20:08:15] [INFO] ℹ️ Tabelas Mapeadas: srag_prod.gold.gold_srag_daily, srag_prod.gold.gold_srag_monthly\n"
     ]
    }
   ],
   "source": [
    "# Arquitetura dos dados\n",
    "\n",
    "CATALOG = \"srag_prod\" \n",
    "SCHEMA = \"gold\"       \n",
    "VOLUME_NAME = \"volume_imagens\" # Storage para arquivos não estruturados (png)\n",
    "\n",
    "# Garante a existência do volume para persistência dos gráficos gerados pelo agente\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.sql(f\"CREATE VOLUME IF NOT EXISTS {CATALOG}.{SCHEMA}.{VOLUME_NAME}\")\n",
    "\n",
    "VOLUME_PATH = f\"/Volumes/{CATALOG}/{SCHEMA}/{VOLUME_NAME}\"\n",
    "TABLE_DAILY = f\"{CATALOG}.{SCHEMA}.gold_srag_daily\"\n",
    "TABLE_MONTHLY = f\"{CATALOG}.{SCHEMA}.gold_srag_monthly\"\n",
    "\n",
    "log(f\"Ambiente de Dados Configurado.\", \"SYSTEM\")\n",
    "log(f\"Caminho do Volume: {VOLUME_PATH}\", \"INFO\")\n",
    "log(f\"Tabelas Mapeadas: {TABLE_DAILY}, {TABLE_MONTHLY}\", \"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fba5a11f-8e3e-4b63-9541-91e3e6397da6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-01-07 20:08:16] [SYSTEM] ⚙️ Executando Validação de Qualidade de Dados (Data Quality Gate)...\n[2026-01-07 20:08:16] [SUCCESS] ✅ Dados Aprovados: 721 registros validados (2024-2025, Sem Nulos, Sem Negativos).\n"
     ]
    }
   ],
   "source": [
    "# Validação dos dados\n",
    "\n",
    "def run_quality_gate():\n",
    "    \"\"\"\n",
    "    Valida os dados da tabela Gold. Se falhar, interrompe o notebook.\n",
    "    Regras:\n",
    "    1. Apenas anos 2024 e 2025.\n",
    "    2. Sem casos negativos.\n",
    "    3. Sem datas nulas.\n",
    "    \"\"\"\n",
    "    log(\"Executando Validação de Qualidade de Dados (Data Quality Gate)...\", \"SYSTEM\")\n",
    "    \n",
    "    spark = SparkSession.builder.getOrCreate()\n",
    "    \n",
    "    # A função 'sum' conta quantas linhas violam cada regra\n",
    "    query_check = f\"\"\"\n",
    "        SELECT \n",
    "            COUNT(*) as total_linhas,\n",
    "            SUM(CASE WHEN year(data_referencia) NOT IN (2024, 2025) THEN 1 ELSE 0 END) as erro_anos,\n",
    "            SUM(CASE WHEN total_casos < 0 THEN 1 ELSE 0 END) as erro_negativos,\n",
    "            SUM(CASE WHEN data_referencia IS NULL THEN 1 ELSE 0 END) as erro_nulos\n",
    "        FROM {TABLE_DAILY}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Coleta o resultado\n",
    "    check = spark.sql(query_check).collect()[0]\n",
    "    \n",
    "    erros = []\n",
    "    \n",
    "    # 1. Validação de Anos (2024/2025 apenas)\n",
    "    if check['erro_anos'] > 0:\n",
    "        erros.append(f\"Regra de Ano: {check['erro_anos']} registros fora de 2024/2025.\")\n",
    "        \n",
    "    # 2. Validação de Negativos\n",
    "    if check['erro_negativos'] > 0:\n",
    "        erros.append(f\"Regra de Negativos: {check['erro_negativos']} registros com casos negativos.\")\n",
    "        \n",
    "    # 3. Validação de Nulos\n",
    "    if check['erro_nulos'] > 0:\n",
    "        erros.append(f\"Regra de Nulos: {check['erro_nulos']} registros com data vazia.\")\n",
    "        \n",
    "    # Verifica se houve algum erro\n",
    "    if erros:\n",
    "        msg_erro = \"\\n\".join(erros)\n",
    "        log(f\"FALHA CRÍTICA DE DATA QUALITY:\\n{msg_erro}\", \"ERROR\")\n",
    "        raise ValueError(f\"\uD83D\uDEA8 O notebook foi interrompido para segurança dos dados.\")\n",
    "    \n",
    "    log(f\"Dados Aprovados: {check['total_linhas']} registros validados (2024-2025, Sem Nulos, Sem Negativos).\", \"SUCCESS\")\n",
    "\n",
    "# Roda a validação\n",
    "run_quality_gate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d34703f-4fe1-4a59-9a10-7965c2a23469",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-01-07 20:08:17] [SYSTEM] ⚙️ Teste Unitário - Métricas:\n{\"data_referencia\": \"2025-12-21\", \"total_casos\": 4, \"taxa_aumento_casos_perc\": -33.33, \"taxa_mortalidade_perc\": 0.0, \"taxa_ocupacao_uti_perc\": 25.0, \"taxa_vacinacao_pacientes_perc\": 25.0, \"analysis_scope\": \"short_term\", \"comparison_window\": \"daily_vs_previous\", \"data_nature\": \"preliminary\"}\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "{\"trace_id\": \"tr-d08378236bdf8582eafb92d660f56ef3\", \"sql_warehouse_id\": null}",
      "text/plain": [
       "Trace(trace_id=tr-d08378236bdf8582eafb92d660f56ef3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Query e Teste Unitário\n",
    "\n",
    "@tool\n",
    "def get_latest_srag_metrics() -> str:\n",
    "    \"\"\"\n",
    "    Consulta o banco de dados para obter as métricas mais recentes de SRAG.\n",
    "    Retorna: Um JSON com total de casos, e taxas de mortalidade, UTI e vacinação.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # log(\"Consultando métricas no Lakehouse...\", \"TOOL\") # Opcional: Descomentar se quiser muito detalhe\n",
    "        spark = SparkSession.builder.getOrCreate()\n",
    "        \n",
    "        query = f\"\"\"\n",
    "        SELECT \n",
    "            cast(data_referencia as string) as data_referencia,\n",
    "            cast(total_casos as int) as total_casos,\n",
    "            cast(taxa_aumento_casos_perc as double) as taxa_aumento_casos_perc,\n",
    "            cast(taxa_mortalidade_perc as double) as taxa_mortalidade_perc,\n",
    "            cast(taxa_ocupacao_uti_perc as double) as taxa_ocupacao_uti_perc,\n",
    "            cast(taxa_vacinacao_pacientes_perc as double) as taxa_vacinacao_pacientes_perc\n",
    "        FROM {TABLE_DAILY}\n",
    "        ORDER BY data_referencia DESC\n",
    "        LIMIT 1\n",
    "        \"\"\"\n",
    "        \n",
    "        df = spark.sql(query).toPandas()\n",
    "        \n",
    "        if df.empty:\n",
    "            log(\"ALERTA: Tabela vazia ao buscar métricas.\", \"WARN\")\n",
    "            return \"ALERTA: A tabela SQL retornou vazio. Verifique se o pipeline rodou.\"\n",
    "            \n",
    "        result = df.iloc[0].to_dict()\n",
    "\n",
    "        # Enriquecimento semântico \n",
    "        result[\"analysis_scope\"] = \"short_term\"\n",
    "        result[\"comparison_window\"] = \"daily_vs_previous\"\n",
    "        result[\"data_nature\"] = \"preliminary\"\n",
    "\n",
    "        return json.dumps(result, ensure_ascii=False)\n",
    "\n",
    "    except Exception as e:\n",
    "        log(f\"Erro na Tool de Métricas: {str(e)}\", \"ERROR\")\n",
    "        return f\"ERRO CRÍTICO NO SPARK/SQL: {str(e)}\"\n",
    "\n",
    "# Teste manual imediato\n",
    "log(\"Teste Unitário - Métricas:\", \"SYSTEM\")\n",
    "print(get_latest_srag_metrics.invoke({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f982fbb-f875-43ca-8115-be05fe6a660e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Visualização\n",
    "\n",
    "@tool\n",
    "def generate_srag_charts() -> str:\n",
    "    \"\"\"\n",
    "    Gera gráficos de linha (30 dias) e barras (12 meses) sobre SRAG.\n",
    "    Padrão de Data:\n",
    "    - Diário: dd/mm (Ex: 28/12)\n",
    "    - Mensal: mm/aaaa (Ex: 12/2024) - Ano com 4 dígitos para evitar confusão com dia.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        log(\"Iniciando geração de gráficos...\", \"TOOL\")\n",
    "        \n",
    "        # GRÁFICO 1: DIÁRIO (30 DIAS) - Linha\n",
    "        query_daily = f\"SELECT data_referencia, total_casos FROM {TABLE_DAILY} ORDER BY data_referencia DESC LIMIT 30\"\n",
    "        df_daily = spark.sql(query_daily).toPandas().sort_values('data_referencia')\n",
    "        \n",
    "        path_daily = \"Sem dados diários\"\n",
    "        if not df_daily.empty:\n",
    "            df_daily['data_referencia'] = pd.to_datetime(df_daily['data_referencia'])\n",
    "            \n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.plot(df_daily['data_referencia'], df_daily['total_casos'], marker='o', color='#1f77b4', linewidth=2)\n",
    "            \n",
    "            # Formatação Eixo X (Diário) -> dd/mm\n",
    "            ax1 = plt.gca()\n",
    "            ax1.xaxis.set_major_formatter(mdates.DateFormatter('%d/%m'))\n",
    "            ax1.xaxis.set_major_locator(mdates.DayLocator(interval=2)) \n",
    "            \n",
    "            plt.title('Casos SRAG - Últimos 30 Dias')\n",
    "            plt.ylabel('Casos')\n",
    "            plt.grid(True, linestyle='--', alpha=0.3)\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            path_daily = f\"{VOLUME_PATH}/grafico_diario.png\"\n",
    "            plt.savefig(path_daily)\n",
    "            plt.close()\n",
    "\n",
    "        # GRÁFICO 2: MENSAL (12 MESES) - Barras\n",
    "        query_monthly = f\"SELECT mes_referencia, total_casos FROM {TABLE_MONTHLY} ORDER BY mes_referencia DESC LIMIT 12\"\n",
    "        df_monthly = spark.sql(query_monthly).toPandas().sort_values('mes_referencia')\n",
    "        \n",
    "        path_monthly = \"Sem dados mensais\"\n",
    "        if not df_monthly.empty:\n",
    "            df_monthly['mes_referencia'] = pd.to_datetime(df_monthly['mes_referencia'])\n",
    "            \n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.bar(df_monthly['mes_referencia'], df_monthly['total_casos'], color='#ff7f0e', width=20)\n",
    "            \n",
    "            # Formatação Eixo X (Mensal) -> mm/aaaa (Ex: 01/2025)\n",
    "            ax2 = plt.gca()\n",
    "            ax2.xaxis.set_major_formatter(mdates.DateFormatter('%m/%Y')) \n",
    "            ax2.xaxis.set_major_locator(mdates.MonthLocator(interval=1))\n",
    "            \n",
    "            plt.title('Casos SRAG - Últimos 12 Meses')\n",
    "            plt.ylabel('Casos')\n",
    "            plt.grid(True, axis='y', linestyle='--', alpha=0.3)\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            path_monthly = f\"{VOLUME_PATH}/grafico_mensal.png\"\n",
    "            plt.savefig(path_monthly)\n",
    "            plt.close()\n",
    "\n",
    "        log(f\"Gráficos persistidos no Volume: {path_daily}, {path_monthly}\", \"SUCCESS\")\n",
    "        return f\"Gráficos atualizados salvos em:\\n1. {path_daily}\\n2. {path_monthly}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        log(f\"Falha ao gerar gráficos: {e}\", \"ERROR\")\n",
    "        return f\"ERRO AO GERAR GRÁFICOS: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2529545-d1f7-418c-afb3-88c2144298b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-01-07 20:08:18] [SUCCESS] ✅ API Key do Tavily carregada via Secrets.\n"
     ]
    }
   ],
   "source": [
    "# Contexto dados\n",
    "\n",
    "try:\n",
    "    token = dbutils.secrets.get(scope=\"my_srag_scope\", key=\"tavily_api_key\")\n",
    "    os.environ[\"TAVILY_API_KEY\"] = token\n",
    "    log(\"API Key do Tavily carregada via Secrets.\", \"SUCCESS\")\n",
    "except Exception as e:\n",
    "    log(f\"Erro ao carregar a API Key: {e}\", \"ERROR\")\n",
    "\n",
    "@tool\n",
    "def get_epidemiological_context() -> str:\n",
    "    \"\"\"\n",
    "    Realiza 'Grounding' (Ancoragem) do modelo em dados externos em tempo real.\n",
    "    Estratégia:\n",
    "    1. Busca Macro (Global/OMS) para identificar novas variantes.\n",
    "    2. Busca Micro (Brasil/Fiocruz) para dados epidemiológicos locais.\n",
    "    Isso reduz a chance do modelo inventar contextos.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])\n",
    "        \n",
    "        # Passo 1: Contexto Internacional\n",
    "        log(\"Investigando cenário Global (OMS/CDC)...\", \"TOOL\")\n",
    "        response_global = client.search(\n",
    "            query=\"Global respiratory virus trends WHO CDC influenza covid epidemiological update\", \n",
    "            search_depth=\"basic\", topic=\"news\", max_results=2, include_answer=True\n",
    "        )\n",
    "        \n",
    "        # Passo 2: Contexto Nacional\n",
    "        log(\"Investigando cenário Brasil (InfoGripe/Fiocruz)...\", \"TOOL\")\n",
    "        response_br = client.search(\n",
    "            query=\"Boletim InfoGripe Fiocruz Brasil cenário atual SRAG covid influenza\", \n",
    "            search_depth=\"basic\", topic=\"news\", max_results=3, include_answer=True\n",
    "        )\n",
    "        \n",
    "        # Montagem do Contexto\n",
    "        contexto = f\"\"\"\n",
    "        | RELATÓRIO DE INTELIGÊNCIA EXTERNA |\n",
    "        1. GLOBAL: {response_global.get('answer', 'N/A')}\n",
    "        2. NACIONAL: {response_br.get('answer', 'N/A')}\n",
    "        \n",
    "        FONTES NACIONAIS:\n",
    "        \"\"\"\n",
    "        for res in response_br.get('results', []):\n",
    "            contexto += f\"- {res['title']}: {res['content'][:200]}...\\n\"\n",
    "            \n",
    "        return contexto\n",
    "\n",
    "    except Exception as e:\n",
    "        log(f\"Erro na busca externa: {str(e)}\", \"ERROR\")\n",
    "        return f\"Erro na busca externa: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2119276c-3f38-443d-8d0f-51732c12170c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-01-07 20:08:19] [SUCCESS] ✅ Agente configurado e pronto! Modelo: databricks-meta-llama-3-3-70b-instruct\n"
     ]
    }
   ],
   "source": [
    "# Definição do Agente\n",
    "\n",
    "# 1. Configuração do Modelo: O parâmetro 'model' define qual endpoint de inferência será acionado.\n",
    "llm = ChatDatabricks(model=\"databricks-meta-llama-3-3-70b-instruct\")\n",
    "\n",
    "# 2. Binding das Ferramentas\n",
    "# O Agente precisa de uma lista de 'tools' disponíveis para saber o que ele pode fazer.\n",
    "tools = [get_latest_srag_metrics, generate_srag_charts, get_epidemiological_context]\n",
    "\n",
    "# 3. Criação do Executor (runtime que pega o pensamento do LLM e efetivamente roda as ferramentas Python).\n",
    "try:\n",
    "    agent_executor = create_agent(llm, tools)\n",
    "    log(f\"Agente configurado e pronto! Modelo: {llm.model}\", \"SUCCESS\")\n",
    "except Exception as e:\n",
    "    log(f\"Erro ao criar agente: {e}\", \"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e69fc1f5-0112-443e-a7b0-40fe031fa9ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-01-07 20:22:55] [SYSTEM] ⚙️ Iniciando ciclo de análise do Agente...\n[2026-01-07 20:22:56] [TOOL] \uD83D\uDEE0️ Ferramenta acionada: get_latest_srag_metrics\n[2026-01-07 20:22:56] [TOOL] \uD83D\uDEE0️ Iniciando geração de gráficos...\n[2026-01-07 20:22:58] [SUCCESS] ✅ Gráficos persistidos no Volume: /Volumes/srag_prod/gold/volume_imagens/grafico_diario.png, /Volumes/srag_prod/gold/volume_imagens/grafico_mensal.png\n[2026-01-07 20:22:58] [TOOL] \uD83D\uDEE0️ Ferramenta acionada: generate_srag_charts\n[2026-01-07 20:22:58] [TOOL] \uD83D\uDEE0️ Investigando cenário Global (OMS/CDC)...\n[2026-01-07 20:22:58] [TOOL] \uD83D\uDEE0️ Investigando cenário Brasil (InfoGripe/Fiocruz)...\n[2026-01-07 20:22:59] [TOOL] \uD83D\uDEE0️ Ferramenta acionada: get_epidemiological_context\n\n--- [AGENTE PENSANDO / RESPOSTA] ---\nAnálise dos Dados Internos (DataSUS)\n\nDe acordo com os dados mais recentes, o total de casos de SRAG é de 4, com uma taxa de aumento de casos de -33,33%, indicando uma redução de 33,33% nos casos. A taxa de mortalidade é de 0,0%, e não houve registro de óbitos no período analisado. A taxa de ocupação de UTI é de 25,0%, e a taxa de vacinação dos pacientes é de 25,0%. \n\nÉ importante considerar que esses dados são preliminares e podem ser influenciados por atrasos de notificação.\n\nPanorama Global\n\nNo cenário global, há relatos de aumento na atividade de vírus respiratórios nos Estados Unidos, com destaque para o aumento nos casos de gripe e COVID-19. Além disso, foi identificada uma nova cepa de influenza, conhecida como \"super flu\", que não parece causar doença mais severa. \n\nCenário Brasil (InfoGripe/Fiocruz)\n\nNo Brasil, de acordo com o Boletim InfoGripe Fiocruz, 32 estados e jurisdições apresentam níveis altos ou muito altos de atividade de gripe. É fundamental estar atento aos sintomas da gripe, como febre, tosse, dor de garganta, dores no corpo e fadiga, e buscar atendimento médico imediato em caso de sintomas severos.\n\nConclusão Técnica\n\nOs dados indicam uma redução nos casos de SRAG, com taxa de aumento de casos negativa. No entanto, é crucial manter a vigilância devido à possibilidade de atrasos de notificação e à natureza preliminar dos dados. Além disso, o cenário global e nacional sugere um aumento na atividade de vírus respiratórios, reforçando a importância da vigilância e do monitoramento contínuo.\n\n==================================================\n[2026-01-07 20:23:04] [SUCCESS] ✅ Processo finalizado às 20:23:04\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "{\"trace_id\": \"tr-bae47d7eb14b7887b168340c81646ab0\", \"sql_warehouse_id\": null}",
      "text/plain": [
       "Trace(trace_id=tr-bae47d7eb14b7887b168340c81646ab0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Execução final\n",
    "\n",
    "from langchain_core.messages import SystemMessage\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "# 1. Configuração de Data/Hora\n",
    "fuso_br = timezone(timedelta(hours=-3))\n",
    "data_hora = datetime.now(fuso_br).strftime(\"%d/%m/%Y às %H:%M\")\n",
    "\n",
    "# 2. Definição do System Prompt\n",
    "system_instructions = \"\"\"\n",
    "ATENÇÃO: Você deve seguir este roteiro de forma estrita.\n",
    "\n",
    "ORDEM DE EXECUÇÃO\n",
    "1. Chame as ferramentas internas:\n",
    "   - get_latest_srag_metrics\n",
    "   - generate_srag_charts\n",
    "2. Chame a ferramenta externa:\n",
    "   - get_epidemiological_context\n",
    "   Aguarde o retorno e use apenas o texto recebido.\n",
    "\n",
    "REGRAS DE LINGUAGEM\n",
    "- O campo taxa_aumento_casos_perc representa variação percentual.\n",
    "- Valores negativos indicam queda.\n",
    "- É proibido usar expressões como:\n",
    "  \"aumento negativo\", \"taxa de aumento negativa\" ou \"aumento de -X%\".\n",
    "- Use apenas:\n",
    "  \"redução de X%\", \"queda de X%\" ou \"os casos diminuíram X%\".\n",
    "\n",
    "REGRAS EPIDEMIOLÓGICAS\n",
    "- Comparações entre períodos recentes (diário ou último período disponível)\n",
    "  devem ser descritas apenas como:\n",
    "  \"sinal recente\", \"variação pontual\" ou \"movimento de curto prazo\".\n",
    "- Não use a palavra \"tendência\" para análises de curto prazo.\n",
    "- Não faça inferências causais ou preditivas.\n",
    "- Se o número de casos for baixo ou o período for recente:\n",
    "  - Use linguagem condicional.\n",
    "  - Declare que os dados são preliminares.\n",
    "  - Cite possível atraso de notificação (apenas uma vez).\n",
    "\n",
    "REGRA ABSOLUTA SOBRE MORTALIDADE\n",
    "- Se o número de óbitos for igual a zero:\n",
    "  - NÃO use os termos \"taxa de mortalidade\" ou \"0%\".\n",
    "  - Use exclusivamente a frase:\n",
    "    \"Não houve registro de óbitos no período analisado.\"\n",
    "- Não complemente.\n",
    "- Não explique.\n",
    "- Não faça conversões numéricas.\n",
    "- Qualquer violação invalida a resposta.\n",
    "\n",
    "ESTRUTURA DO RELATÓRIO\n",
    "\n",
    "Análise dos Dados Internos (DataSUS)\n",
    "- Comece pelos valores observados:\n",
    "  total de casos, UTI, vacinação e óbitos.\n",
    "- Em seguida, descreva a variação percentual (queda ou aumento).\n",
    "- Finalize com uma única frase de cautela\n",
    "  (curto prazo, dados preliminares, atraso de notificação).\n",
    "- Se não houver óbitos, use apenas a frase obrigatória.\n",
    "\n",
    "Panorama Global\n",
    "- Resuma apenas o conteúdo retornado pela ferramenta externa.\n",
    "- Não extrapole nem interprete além do texto recebido.\n",
    "\n",
    "Cenário Brasil (InfoGripe/Fiocruz)\n",
    "- Resuma apenas o conteúdo retornado pela ferramenta externa.\n",
    "- Se não houver informação, informe que a ferramenta não retornou dados.\n",
    "\n",
    "Conclusão Técnica\n",
    "- Texto curto, objetivo e cauteloso.\n",
    "- Não use \"tendência\" se baseado em curto prazo.\n",
    "- Evite afirmações absolutas.\n",
    "\"\"\"\n",
    "\n",
    "log(f\"Iniciando ciclo de análise do Agente...\", \"SYSTEM\")\n",
    "\n",
    "# 3. Montagem do Payload\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        SystemMessage(content=system_instructions),\n",
    "        # Aqui entra o PROMPT DO USUÁRIO\n",
    "        (\"user\", \"Gere o relatório de monitoramento SRAG de hoje.\")\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 4. Execução com Logs Detalhados\n",
    "try:\n",
    "    for chunk in agent_executor.stream(inputs, stream_mode=\"values\", config={\"recursion_limit\": 25}):\n",
    "        message = chunk[\"messages\"][-1]\n",
    "        \n",
    "        if message.type == \"ai\" and not message.tool_calls:\n",
    "            # Mostra o pensamento ou a resposta final\n",
    "            print(f\"\\n--- [AGENTE PENSANDO / RESPOSTA] ---\\n{message.content}\")\n",
    "        elif message.type == \"tool\":\n",
    "            log(f\"Ferramenta acionada: {message.name}\", \"TOOL\")\n",
    "    \n",
    "    hora_fim = datetime.now(fuso_br).strftime(\"%H:%M:%S\")\n",
    "    print(\"\\n\" + (\"=\" * 50))\n",
    "    log(f\"Processo finalizado às {hora_fim}\", \"SUCCESS\")\n",
    "\n",
    "except Exception as e:\n",
    "    log(f\"Erro na execução do loop do agente: {e}\", \"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0633c2ef-42c1-41d4-97bc-e2044dd49461",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-01-07 20:08:30] [INFO] ℹ️ Iniciando registro de auditoria no MLflow...\n[2026-01-07 20:08:31] [INFO] ℹ️ Texto do relatório salvo: relatorio_srag.md\n[2026-01-07 20:08:32] [SUCCESS] ✅ Artefatos visuais (Gráficos) anexados ao experimento.\n----------------------------------------------------------------------------------------------------\n[2026-01-07 20:08:32] [SUCCESS] ✅ Sucesso! Execução auditada no MLflow.\n[2026-01-07 20:08:32] [INFO] ℹ️ Link para Experiment: /Users/eduardobdel@gmail.com/srag_agent_monitoring\n"
     ]
    }
   ],
   "source": [
    "# Registro de Execução\n",
    "\n",
    "# Salvar o resultado do agente\n",
    "with mlflow.start_run(run_name=\"Relatorio Diario SRAG\") as run:\n",
    "    log(\"Iniciando registro de auditoria no MLflow...\", \"INFO\")\n",
    "    \n",
    "    # 1. Logamos os Parâmetros\n",
    "    mlflow.log_param(\"data_execucao\", data_hora)\n",
    "    mlflow.log_param(\"modelo_usado\", \"llama-3-70b\")\n",
    "    \n",
    "    # 2. Log do Texto Final\n",
    "    nome_arquivo_relatorio = \"relatorio_srag.md\"\n",
    "    \n",
    "    # Pega a última mensagem válida do loop anterior\n",
    "    # (Nota: Assume que a variável 'message' ainda está na memória da célula anterior)\n",
    "    try:\n",
    "        texto_final = message.content \n",
    "        mlflow.log_text(texto_final, nome_arquivo_relatorio)\n",
    "        log(f\"Texto do relatório salvo: {nome_arquivo_relatorio}\", \"INFO\")\n",
    "    except NameError:\n",
    "        log(\"Variável 'message' não encontrada. O agente rodou?\", \"WARN\")\n",
    "    \n",
    "    # 3. Logamos os Gráficos. O MLflow copia as imagens do Volume para dentro do Experimento\n",
    "    try:\n",
    "        mlflow.log_artifact(f\"{VOLUME_PATH}/grafico_diario.png\", artifact_path=\"graficos\")\n",
    "        mlflow.log_artifact(f\"{VOLUME_PATH}/grafico_mensal.png\", artifact_path=\"graficos\")\n",
    "        log(\"Artefatos visuais (Gráficos) anexados ao experimento.\", \"SUCCESS\")\n",
    "    except Exception as e:\n",
    "        log(f\"Não foi possível logar as imagens: {e}\", \"WARN\")\n",
    "\n",
    "    print(\"-\" * 100)\n",
    "    log(\"Sucesso! Execução auditada no MLflow.\", \"SUCCESS\")\n",
    "    log(f\"Link para Experiment: {experiment_path}\", \"INFO\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "srag_agent_v1",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
